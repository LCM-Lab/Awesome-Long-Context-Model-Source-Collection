### üìö Survey Papers Collection

This repository is a curated list of survey papers for Long-context Data. 
ËøôÈáåÈúÄË¶ÅÂÜô‰∏Ä‰∏™Â§ßÊ†áÈ¢òÔºàabstractÔºâ

---

## üîç Navigation

Click on the links below to jump directly to each section:

- [Tutorial](./README_tutorial.md)

---

## üßæ Repository Structure ÔºàËøôÈáåÈúÄË¶ÅÊ†πÊçÆ‰∏ãÈù¢ÂÜôÁöÑÂÜÖÂÆπ‰øÆÊîπÔºâ

```
survey-papers/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ computer-vision/
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ nlp/
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ machine-learning/
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ ...
```

---

## üìú Papers

> You can directly click on the title to jump to the corresponding PDF link location

### 1. Survey Papers

1. [**A Survey on Long Text Modeling with Transformers.**](https://arxiv.org/abs/2302.14502) _Zican Dong, Tianyi Tang, Lunyi Li, Wayne Xin Zhao._ Arxiv 2023.

2. [**Thus Spake Long-Context Large Language Model.**](https://arxiv.org/abs/2502.17129) _Xiaoran Liu, Ruixiao Li, Mianqiu Huang, Zhigeng Liu, Yuerong Song, Qipeng Guo, Siyang He, Qiqi Wang, Linlin Li, Qun Liu, Yaqian Zhou, Xuanjing Huang, Xipeng Qiu._ Arxiv 2025. [![GitHub Repo stars](https://img.shields.io/github/stars/OpenMOSS/Thus-Spake-Long-Context-LLM)](https://github.com/OpenMOSS/Thus-Spake-Long-Context-LLM)

3. [**A Comprehensive Survey on Long Context Language Modeling.**](https://arxiv.org/abs/2503.17407) _Jiaheng Liu, Dawei Zhu, Zhiqi Bai, Yancheng He, Huanxuan Liao, Haoran Que, Zekun Wang, Chenchen Zhang, Ge Zhang, Jiebin Zhang, Yuanxing Zhang, Zhuo Chen, Hangyu Guo, Shilong Li, Ziqiang Liu, Yong Shan, Yifan Song, Jiayi Tian, Wenhao Wu, Zhejian Zhou, Ruijie Zhu, Junlan Feng, Yang Gao, Shizhu He, Zhoujun Li, Tianyu Liu, Fanyu Meng, Wenbo Su, Yingshui Tan, Zili Wang, Jian Yang, Wei Ye, Bo Zheng, Wangchunshu Zhou, Wenhao Huang, Sujian Li, Zhaoxiang Zhang._ Arxiv 2025. [![GitHub Repo stars](https://img.shields.io/github/stars/LCLM-Horizon/A-Comprehensive-Survey-For-Long-Context-Language-Modeling)](https://github.com/LCLM-Horizon/A-Comprehensive-Survey-For-Long-Context-Language-Modeling)

### 2. LCMs Training Data

#### 2.1 Pre-Training Data

#### 2.2 Post-Training Data

### 3. LCMs Evaluation Benchmarks

#### 3.1 General Capabilities

#### 3.2 Retrieval Capabilities

#### 3.3 Reasoning Capabilities

#### 3.4 Aggravation Capabilities

#### 3.5 Long-Form Generation Capabilities

1. [**LongGenBench: Benchmarking Long-Form Generation in Long Context LLMs.**](https://arxiv.org/abs/2409.02076) _Yuhao Wu, Ming Shan Hee, Zhiqing Hu, Roy Ka-Wei Lee._ Arxiv 2024. [![GitHub Repo stars](https://img.shields.io/github/stars/mozhu621/LongGenBench)](https://github.com/mozhu621/LongGenBench/)

2. 
---

## ‚úÖ Contributing

Contributions are welcome! If you'd like to add a new category or improve an existing one:

1. Fork the repo.
2. Create a new branch (`git checkout -b feature/new-category`).
3. Make your changes.
4. Commit and push your changes.
5. Open a pull request.

Please follow the contribution guidelines (you can create a `CONTRIBUTING.md` file for details).

---

## üìå License

This project is licensed under the MIT License ‚Äî see the [LICENSE](LICENSE) file for details.

---

## ü§ù Contact

If you have any questions or suggestions, feel free to open an issue or contact me at [your-email@example.com].
